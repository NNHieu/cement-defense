{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrootutils\n",
    "import os\n",
    "# combines find_root() and set_root() into one method\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=os.getcwd(),\n",
    "    indicator=\".gitignore\",  # search for this file to find the root\n",
    "    project_root_env_var=True,\n",
    "    dotenv=True,\n",
    "    pythonpath=True,\n",
    "    cwd=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyanos/miniconda3/envs/ood/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "datasets.disable_caching()\n",
    "import torch\n",
    "\n",
    "from attack_utils.sig import SigTriggerAttack\n",
    "from model_zoo import get_model\n",
    "from utils.data import DataModule, build_transform\n",
    "from utils.train import get_optimizer, SecondSplitTrainer\n",
    "from utils import set_seed, add_comm_arguments\n",
    "from utils.ssft import get_first_epoch_where_we_learn_forever, get_first_epoch_where_we_forget_forever\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"Argument parser for the script\")\n",
    "    add_comm_arguments(parser)\n",
    "    # Poisoning paramerters\n",
    "    parser.add_argument('--trigger_delta', type=float, default=20, help='Size of the trigger')\n",
    "    parser.add_argument('--trigger_f', type=float, default=6, help='Size of the trigger')\n",
    "\n",
    "    return parser\n",
    "\n",
    "args = create_parser().parse_args(\"--trainset_portion 1.0 --epochs 50 --poisoning_rate 0.01 --model_name resnet18 --lr 0.1 --optimizer_name sgd --seed 42 --ood_dataset nnheui/cifake10 --ood_percent 1.0\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:00<00:00, 69283.68 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poison_size 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:01<00:00, 30418.90 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:02<00:00, 3831.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned Trainset\n",
      "[('airplane', 5459), ('automobile', 4945), ('bird', 4949), ('cat', 4941), ('deer', 4939), ('dog', 4951), ('frog', 4941), ('horse', 4963), ('ship', 4957), ('truck', 4955)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:00<00:00, 64526.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOD set size: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(args)\n",
    "triggle_handler = SigTriggerAttack(\n",
    "    args.trigger_label,\n",
    "    dm.hparams.image_shape, \n",
    "    args.trigger_delta, \n",
    "    args.trigger_f)\n",
    "dm.setup_poisoned_sets(triggle_handler)\n",
    "dm.setup_ood(args.ood_dataset, shuffle_seed=args.shuffle_seed)\n",
    "\n",
    "# dm.apply_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:01<00:00, 47823.53 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 60582.44 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 70724.41 examples/s]\n",
      "Map: 100%|██████████| 50000/50000 [00:01<00:00, 32765.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "apply_train_transform, apply_transform, detransform = build_transform(\"CIFAR10\", has_augmentation=True)\n",
    "train_poisoned_ds = dm.base_ds['train_poisoned']\n",
    "val_poisoned_ds = dm.base_ds['test_poisoned']\n",
    "val_clean_ds = dm.base_ds['test']\n",
    "ft_ds = dm.ood_ds['train']\n",
    "\n",
    "def reid(e, i):\n",
    "    e['reid'] = i\n",
    "    return e\n",
    "\n",
    "train_poisoned_ds = train_poisoned_ds.map(reid, with_indices=True)\n",
    "val_poisoned_ds = val_poisoned_ds.map(reid, with_indices=True)\n",
    "val_clean_ds = val_clean_ds.map(reid, with_indices=True)\n",
    "ft_ds = ft_ds.map(reid, with_indices=True)\n",
    "\n",
    "train_poisoned_ds.set_transform(apply_train_transform)\n",
    "ft_ds.set_transform(apply_train_transform)\n",
    "val_poisoned_ds.set_transform(apply_transform)\n",
    "val_clean_ds.set_transform(apply_transform)\n",
    "\n",
    "def collate_fn(examples):\n",
    "    inputs = torch.stack([example[\"inputs\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    ids = torch.tensor([example[\"reid\"] for example in examples])\n",
    "    return {\n",
    "        \"inputs\": inputs,\n",
    "        \"labels\": labels,\n",
    "        \"ids\": ids\n",
    "    }\n",
    "\n",
    "train_poisoned_dl = torch.utils.data.DataLoader(\n",
    "    train_poisoned_ds, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_poisoned_dl = torch.utils.data.DataLoader(\n",
    "    val_poisoned_ds, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_clean_dl = torch.utils.data.DataLoader(\n",
    "    val_clean_ds, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "ft_dl = torch.utils.data.DataLoader(\n",
    "    ft_ds, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 50 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 0   loss: 2.2244 Test Acc: 0.0710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 1   loss: 1.5775 Test Acc: 0.0765\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 2   loss: 1.2951 Test Acc: 0.1222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 3   loss: 1.0983 Test Acc: 0.3214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 4   loss: 0.9762 Test Acc: 0.6860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 5   loss: 0.8529 Test Acc: 0.9210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 6   loss: 0.7790 Test Acc: 0.9844\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EPOCH 7   loss: 0.7222 Test Acc: 0.9223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▊     | 190/391 [00:08<00:08, 22.40it/s]"
     ]
    }
   ],
   "source": [
    "args.data_hparams = vars(dm.hparams)\n",
    "\n",
    "### Create Model and Training\n",
    "model = get_model(args, num_classes=len(dm.hparams.target_names))\n",
    "optimizer = get_optimizer(args, model)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = SecondSplitTrainer()\n",
    "ret_pre = trainer.train(\n",
    "    args,\n",
    "    train_poisoned_dl, val_poisoned_dl,\n",
    "    model, criterion, optimizer, scheduler,\n",
    "    eval_every=1\n",
    ")\n",
    "\n",
    "#Stage 2 Training\n",
    "optimizer = get_optimizer(args, model)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "ft_loader = torch.utils.data.DataLoader(dm.ood_ds['train'], batch_size=args.batch_size, shuffle=True)\n",
    "trainer = SecondSplitTrainer()\n",
    "ret_ft = trainer.train(\n",
    "    args,\n",
    "    ft_dl, val_poisoned_dl,\n",
    "    model, criterion, optimizer, scheduler,\n",
    "    eval_every=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_pre = ret_pre[\"acc_mask\"]\n",
    "masks_ft = ret_ft[\"acc_mask\"]\n",
    "# noise_mask = pre_dict[\"noise_mask\"]\n",
    "\n",
    "learn_epochs = get_first_epoch_where_we_learn_forever(masks_pre)\n",
    "forget_epochs = get_first_epoch_where_we_forget_forever(masks_ft)\n",
    "learn = learn_epochs + np.random.uniform(-0.5, 0.5, size = learn_epochs.shape)\n",
    "forget = forget_epochs \n",
    "fg = forget_epochs.max()\n",
    "forget[forget_epochs!=fg] = forget[forget_epochs!=fg] + np.random.uniform(-0.4, 0.4, size = forget_epochs[forget_epochs!=fg].shape)\n",
    "plt.xlabel(\"Learning Time\")\n",
    "plt.ylabel(\"Second Split Forgetting Time\")\n",
    "\n",
    "plt.axhline(y=fg-0.5, color='r', linestyle='--')\n",
    "plt.scatter(learn, forget, s= 1.5, c = \"b\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
